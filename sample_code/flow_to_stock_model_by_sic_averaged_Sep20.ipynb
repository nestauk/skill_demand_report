{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this script does:\n",
    "1. Load the full dataset of vacancies and merge with the SOC letters that have been estimated for each vacancy\n",
    "2. Compute the un-weighted monthly stock of online job adverts (OJA) vacancies broken down by SIC\n",
    "3. Compute the per-vacancy weights to align with the ONS vacancy dataset\n",
    "4. Compute the adjusted per-vacancy weights after taking into account adverts with \"uncertain\" SIC letters\n",
    "5. Save the results for future analysis\n",
    "\n",
    "Note on the presence of adverts with \"uncertain\" SIC letters. \n",
    "- First of all, these adverts are assigned the median weight for that month. The same is true for job adverts with SIC codes that are not measured by the ONS vacancy survey. This affects the total stock count, which is now higher than the ONS one because the overall sum includes vacancies that were not used to compute the per-vacancy weights. However, we adjust for this, otherwise breakdowns by other characteristics might be artificially inflated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------ DEPENDENCIES AND FUNCTIONS ------------------------\n",
    "\n",
    "# standard imports\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import sys\n",
    "import statsmodels as sm\n",
    "from time import time as tt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# custom imports\n",
    "from flow_to_stock_funcs import get_stock_breakdown, load_ons_vacancies, \\\n",
    "                                set_month_at_beginning, set_month_at_end, scale_weights_by_total_levels\n",
    "from textkernel_load_utils import tk_params, create_tk_import_dict, read_and_append_chunks, \\\n",
    "                                  load_full_column, data_path, data_folder\n",
    "from utils_general import nesta_colours, flatten_lol, sic_letter_to_text, print_elapsed, TaskTimer, printdf\n",
    "\n",
    "# Add custom SIC groups\n",
    "sic_letter_to_text['Z'] = 'others'\n",
    "sic_letter_to_text['L_O_S'] = 'personal_and_public_services'\n",
    "sic_letter_to_text['D_E'] = 'utilities'\n",
    "sic_letter_to_text['M_P'] = 'educational_and_professional_activities'\n",
    "sic_letter_to_text['uncertain'] = 'uncertain'\n",
    "\n",
    "# NOTE: change to local results folder\n",
    "res_folder = '/path/to/results'\n",
    "\n",
    "timer = TaskTimer()\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardcoded parameters setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_DURATION_TH = 55\n",
    "TEST_DURATION_TH = 1\n",
    "CONSTANT_DUR = False\n",
    "DURATION_TH = TEST_DURATION_TH if CONSTANT_DUR else FIXED_DURATION_TH\n",
    "START_MONTH = '2015-03'\n",
    "END_MONTH= '2019-11'\n",
    "FIRST_VALID_MONTH = '2015-05'\n",
    "print(f'Duration threshold is {DURATION_TH}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions, parameters and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def norm_series(df_series):\n",
    "    \"\"\" Standardise a time series\"\"\"\n",
    "    return (df_series - df_series.mean())/df_series.std()\n",
    "\n",
    "#%%\n",
    "def cap_duration(data, duration_th = 55):\n",
    "    \"\"\" Durations longer than 55 days are set at 55 days\"\"\"\n",
    "    data.loc[data.duration>duration_th,'duration'] = duration_th\n",
    "    return data\n",
    "\n",
    "# invert the sic letter to text mapping\n",
    "sic_text_to_letter = {v: k for k,v in sic_letter_to_text.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get which TK ID value for sector corresponds to which label\n",
    "def get_map_industry_label_values():\n",
    "    \"\"\" \"\"\"\n",
    "    tmp_data = pd.read_csv(os.path.join(data_folder, tk_params.file_name_template.format(0)), \n",
    "                           compression='gzip',\n",
    "                encoding = 'utf-8',usecols = ['organization_industry_label','organization_industry_value'])\n",
    "    map_label2value = {}\n",
    "    map_value2label = {}\n",
    "    for name,g in tmp_data.groupby('organization_industry_value'):\n",
    "        map_value2label[name] = g.organization_industry_label.value_counts().index.values[0]\n",
    "        map_label2value[map_value2label[name]] = name\n",
    "    return map_label2value, map_value2label\n",
    "\n",
    "# create the maps\n",
    "map_label2value, map_value2label = get_map_industry_label_values()\n",
    "\n",
    "map_label2value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def get_top_month(x):\n",
    "    \"\"\"Get month in which a vacancy is most active based on a string \n",
    "    listing all the months in which the vacancy is active\n",
    "    \"\"\"\n",
    "    if isinstance(x,str):\n",
    "        x = x.split(';')[1:]\n",
    "    else:\n",
    "        x = x.active_months.split(';')[1:]\n",
    "    months = [t.split(': ')[0].split(' ')[1] for t in x]\n",
    "    durations = [t.split(': ')[1] for t in x]\n",
    "    # if multiple maxes it'll return the first one, which seems reasonable\n",
    "    if len(durations):\n",
    "        best_idx = np.argmax(durations)\n",
    "        return months[best_idx]#, durations[best_idx]\n",
    "    else:\n",
    "        return 'oob'\n",
    "\n",
    "def get_top_duration(x):\n",
    "    \"\"\"Get the amount of time a vacancy is active in its top month\n",
    "    based on a string listing all the months in which the vacancy is active\n",
    "    with respective durations\n",
    "    \"\"\"\n",
    "    if isinstance(x,str):\n",
    "        if x == 'oob':\n",
    "            return 0\n",
    "        x = x.split(';')[1:]\n",
    "    else:\n",
    "        if x.active_months == 'oob':\n",
    "            return 0\n",
    "        x = x.active_months.split(';')[1:]\n",
    "    months = [t.split(': ')[0] for t in x]\n",
    "    durations = [t.split(': ')[1] for t in x]\n",
    "    # if multiple maxes it'll return the first one, which seems reasonable\n",
    "    best_idx = np.argmax(durations)\n",
    "    return durations[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def twin_plot(ons_data,ojv_data,xlims = [pd.to_datetime(START_MONTH + '-01'),\n",
    "                                         pd.to_datetime(END_MONTH + '-01')]):\n",
    "    \n",
    "    \"\"\" Plot two timeseries on same axis (ONS vacancies and (un-)weighted stock)\"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('date (year-month)')\n",
    "    ax1.set_ylabel('ONS vacancy stock', color=color)\n",
    "    ax1.plot(ons_data, 'x-', color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('OJA vacancy stock', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(ojv_data, 'o-', color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(raw_jvs) #norm_series(raw_jvs))\n",
    "    #plt.plot(norm_series(stock_month1)) #df_stock))\n",
    "    plt.xlim(xlims[0],xlims[1])\n",
    "    fig.tight_layout()\n",
    "    return fig, ax1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online vacancy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration, start date, soc code and organisation name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Usually would load Textkernel dataset')\n",
    "data_df = ['main_dataset']\n",
    "#%% get beginning and ending of the collection period\n",
    "first_date = data_df.date.min()\n",
    "last_date = data_df.date.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-vacancy SIC code\n",
    "\n",
    "Note:\n",
    "We made an algorithm that assigned a SIC code to each vacancy based on a combination of methods. The main part of the algorithm was run separately and produced a set of candindates SIC per vacancies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SIC letters column\n",
    "data_df += ['final_sic_letter'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composition of job adverts by SIC letter\n",
    "data_df.final_sic_letter.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ONS data on vacancies\n",
    "raw_jvs_full, jvs_sic_letters = load_ons_vacancies(f\"{data_path}/data\")\n",
    "# Change all the columns names\n",
    "raw_jvs_full = raw_jvs_full.rename(columns = {t: jvs_sic_letters.loc[t] for t in jvs_sic_letters.index})\n",
    "\n",
    "printdf(raw_jvs_full.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that are not needed\n",
    "raw_jvs = raw_jvs_full.drop(['D','E', 'G45', 'G46', 'G47', 'L', 'M', 'O', 'P', 'S', 'G46_47'] , axis = 1)\n",
    "\n",
    "printdf(raw_jvs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and processing of the duration field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEFIGS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick analysis of duration field\n",
    "full_median_duration = data_df.duration.median()\n",
    "tmp = data_df.duration.dropna().value_counts().sort_index()\n",
    "plt.plot(tmp.cumsum()/tmp.sum()*100)\n",
    "plt.xlim([0,100])\n",
    "plt.plot(DURATION_TH,tmp.cumsum()[DURATION_TH]/tmp.sum()*100,'x')\n",
    "plt.xlabel('Duration value')\n",
    "plt.ylabel('Proportion of jobs')\n",
    "print((f'Percentage of filtered job adverts with duration within limit ({DURATION_TH} days is the threshold),'\n",
    "       ' among the ones with a not null duration field:'\n",
    "       f' {tmp.cumsum()[DURATION_TH]/tmp.sum()*100:.2f}%'))\n",
    "if SAVEFIGS:\n",
    "    plt.savefig(f\"{res_folder}/cumulative_sum_of_durations.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# replace \"bad\" duration values (that is, those that are zeros or higher than the threshold)\n",
    "good_durations = (data_df.duration>0) & (data_df.duration<=duration_th)\n",
    "# take the median from those durations that will not be changed\n",
    "median_duration = data_df[good_durations].duration.median()\n",
    "print(f'Median duration to use is {median_duration}')\n",
    "\n",
    "if CONSTANT_DUR:\n",
    "    data_df['duration_to_use'] = DURATION_TH\n",
    "    print(f'Using constant duration of {DURATION_TH}')\n",
    "else:\n",
    "    data_df['duration_to_use'] = data_df.duration.copy()\n",
    "    # replace 0s\n",
    "    data_df.loc[data_df.duration_to_use==0,'duration_to_use'] = median_duration\n",
    "    data_df.loc[data_df.duration_to_use>duration_th,'duration_to_use'] = duration_th\n",
    "    data_df.duration_to_use = data_df.duration_to_use.fillna(median_duration)\n",
    "    sns.distplot(data_df.duration_to_use)\n",
    "\n",
    "assert(data_df.duration_to_use.isna().sum()==0)\n",
    "print(f'Max duration used in the dataset is {data_df.duration_to_use.max()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(re-)compute end date \n",
    "'''\n",
    "Note that I'm using the convention of removing 1 (even though it means I need to shift the removal day by 1 \n",
    "when computing the stock) because a) it makes sense to have the expiration date rather than the removal date\n",
    "and b) that is how the original expiration date is in the TK dataset\n",
    "'''\n",
    "data_df['end_date'] = data_df.date + pd.to_timedelta(\n",
    "        data_df.duration_to_use - 1, unit='D')\n",
    "\n",
    "# initialise weight column with 1\n",
    "data_df['vacancy_weight']= 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow to stock model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and plot un-weighted monthly stock of vacancies against ons vacancies\n",
    "t0 = tt()\n",
    "# new way\n",
    "stock_per_month, stock_per_day, _, _ = get_stock_breakdown(\n",
    "    data_df, agg_func = 'count', agg_col = 'vacancy_weight', breakdown_col = 'final_sic_letter')\n",
    "\n",
    "print_elapsed(t0,'computing daily and monthly stock')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_per_month.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get which SIC codes are in both stocks (ONS and online job adverts)\n",
    "sic_in_common = sorted(set(data_df.final_sic_letter.value_counts().index).intersection(raw_jvs.columns))\n",
    "print(sic_in_common)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot each SIC letters separately: this can only be used to understand whether the trends are similar between OJA and ONS\n",
    "for col in sic_in_common:\n",
    "    if col == 'V':\n",
    "        continue\n",
    "    _ = twin_plot(1e3*raw_jvs[col], stock_per_month[col])\n",
    "    tmp = np.corrcoef(raw_jvs[col].astype('float'),stock_per_month[col])[0,1]\n",
    "    print((f\"Time series correlation for {sic_letter_to_text[col]} is \"\n",
    "           f\"{tmp:.3f}\"))\n",
    "    try:\n",
    "        plt.title(sic_letter_to_text[col].capitalize())\n",
    "    except:\n",
    "        plt.title('others')\n",
    "    if SAVEFIGS:\n",
    "        plt.savefig(f\"{res_folder}/raw_stock_vs_ons_sic_{col}_double_axis.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series of the non-assigned stock\n",
    "plt.plot(stock_per_month['uncertain'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of jobs without a SIC?\n",
    "(data_df.final_sic_letter == 'uncertain').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full list of sectors and which ones are in common with the ONS data \n",
    "oja_names = sorted(stock_per_month.columns)\n",
    "ons_names = [col+'_ons' for col in sorted(raw_jvs.columns) if col in oja_names]\n",
    "shared_oja_names = [t for t in oja_names if t in raw_jvs.columns]\n",
    "extra_oja_names = [t for t in oja_names if t not in shared_oja_names]\n",
    "shared_oja_names, extra_oja_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the uncertain stock separate\n",
    "stock_per_day_full = stock_per_day.copy() #[['A','T','uncertain']]\n",
    "stock_per_month_full = stock_per_month.copy() #[['A','T','uncertain']]\n",
    "\n",
    "# drop the original column\n",
    "stock_per_day = stock_per_day.drop(axis = 1, labels = extra_oja_names) #['A','T','uncertain'])\n",
    "stock_per_month = stock_per_month.drop(axis = 1, labels = extra_oja_names) #['A','T','uncertain'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(stock_per_day<0).sum() #THE STOCK CAN NOT BE NEGATIVE: this should be empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute post-sampling weights to align the two data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------- MONTHLY WEIGHTS ESTIMATES -------------------\n",
    "\n",
    "Compute the ratio between the two stocks per month, from the ONS and from OJA\n",
    "\n",
    "Assign an average weight to the vacancies with uncertain SIC based on their assigned month\n",
    "\n",
    "Assigning per-vacancy weight based on an assigned month and SIC letter\n",
    "\n",
    "Rescale the per-vacancy weight by a monthly factor to increase alignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract needed information for each vacancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all months of interest\n",
    "all_months = pd.date_range(start= START_MONTH, end = END_MONTH, freq = 'M').map(\n",
    "    set_month_at_beginning)\n",
    "\n",
    "# initialise new dataframe - for each vacancy I want to compute the best month\n",
    "# and how long it stays open during that month\n",
    "data_df = data_df.assign(active_months = '')\n",
    "\n",
    "# For each vacancy, get all the months in which it is active and the relative duration\n",
    "for month in tqdm(all_months):\n",
    "    tot_days = month.days_in_month\n",
    "    month_begins = month\n",
    "    month_ends = set_month_at_end(month)\n",
    "    # extract all jobs that are active during this month\n",
    "    jobs_starting_now = data_df.date.between(month_begins, month_ends)\n",
    "    jobs_ending_later = ((data_df.date<month_begins) & (\n",
    "                data_df.end_date>month_begins))\n",
    "    valid_jobs = jobs_starting_now | jobs_ending_later\n",
    "\n",
    "    valid_durations = (data_df[valid_jobs].end_date.map(lambda x: \n",
    "        min([x,month_ends])) - data_df[valid_jobs].date.map(lambda x: \n",
    "        max([x,month_begins]))).map(lambda x: (x.days+1)/tot_days)\n",
    "                                                          \n",
    "    # record the active month\n",
    "    data_df.loc[valid_jobs,'active_months'] = data_df[\n",
    "        valid_jobs].active_months.map(\n",
    "        lambda x: x+ f';month {month.year}-{month.month:02}: ')\n",
    "    # append the durations\n",
    "    data_df.loc[valid_jobs,'active_months'] = data_df[\n",
    "        valid_jobs].active_months + valid_durations.map(lambda x: f'{x:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Add column with best month\n",
    "t0 = tt()\n",
    "data_df['best_month'] = data_df.active_months.map(\n",
    "    get_top_month)\n",
    "\n",
    "#turn all months to beginning of the month timestamp\n",
    "data_df.best_month = pd.to_datetime(data_df.best_month).map(set_month_at_beginning)\n",
    "\n",
    "\n",
    "print_elapsed(t0,'getting the best month')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Add column with the duration of a vacancy in its best month\n",
    "t0 = tt()\n",
    "data_df['best_month_duration'] = data_df.active_months.map(\n",
    "    get_top_duration)\n",
    "data_df.best_month_duration = data_df.best_month_duration.astype('float')\n",
    "print_elapsed(t0,'getting how long vacancies are open in their best months')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the ratio between the two stocks per month, from the ONS and from OJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% # compute weights by months and SIC\n",
    "# join ONS and OJA data\n",
    "joint_stock = raw_jvs[['vacancies']+shared_oja_names].merge(stock_per_month.copy(), how = 'outer',\n",
    "                            suffixes = ('_ons','_counts'),\n",
    "                            left_index = True, right_index=True)\n",
    "\n",
    "for col,ons_col in zip(shared_oja_names,ons_names):\n",
    "    assert(col+'_ons'==ons_col)\n",
    "    joint_stock[col+'_weight'] = joint_stock[ons_col]*1000/joint_stock[col+'_counts'].replace(0,pd.NA)\n",
    "\n",
    "joint_stock = joint_stock[sorted(joint_stock.columns)]\n",
    "\n",
    "joint_stock = joint_stock.replace(np.inf, 0)\n",
    "\n",
    "for col in shared_oja_names:\n",
    "    joint_stock[col+'_weight'] = joint_stock[col+'_weight'].astype('float')\n",
    "\n",
    "# rename the columns\n",
    "joint_stock = joint_stock.rename(columns = {'vacancies': 'vacancies_ons'})#, \n",
    "\n",
    "# replace NaN with the neutral weight (which is 1)\n",
    "joint_stock = joint_stock.fillna(1)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign an average weight to the vacancies with uncertain SIC based on their assigned month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the weight for the 'uncertain' category as the median across all SIC codes\n",
    "# I need to replicate them for all the categories of SIC codes that are not present in the ONS survey\n",
    "joint_stock = joint_stock.assign(uncertain_weight = joint_stock[\n",
    "    [col+'_weight' for col in shared_oja_names]].median(axis = 1))\n",
    "\n",
    "joint_stock = joint_stock.assign(A_weight = joint_stock.uncertain_weight.values)\n",
    "\n",
    "joint_stock = joint_stock.assign(T_weight = joint_stock.uncertain_weight.values)\n",
    "\n",
    "# rename columns for consistency\n",
    "for col in oja_names:\n",
    "    if col not in shared_oja_names:\n",
    "        joint_stock = joint_stock.rename(columns = {col: col+'_counts'})\n",
    "\n",
    "joint_stock = joint_stock[sorted(joint_stock.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_stock.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example weights for agriculture\n",
    "joint_stock.iloc[:5].A_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the monthly weights with the main dataframe \n",
    "That is, Assigning per-vacancy weight based on an assigned month and SIC letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataframe for merging, i.e. put it in long form\n",
    "weights_cols = [col for col in joint_stock.columns if 'weight' in col]\n",
    "joint_stock_weights = joint_stock[weights_cols]\n",
    "joint_stock_weights = joint_stock_weights.reset_index()\n",
    "joint_stock_weights = pd.melt(joint_stock_weights, id_vars='month', \n",
    "                              value_vars = weights_cols,\n",
    "                             value_name='vacancy_weight_adj',\n",
    "                             var_name = 'sic_letter')\n",
    "joint_stock_weights = joint_stock_weights.rename(columns = {'month': 'best_month'})\n",
    "joint_stock_weights.sic_letter = joint_stock_weights.sic_letter.map(lambda x: x[:-7])\n",
    "joint_stock_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%\n",
    "# [if needed] remove weights from previous iterations with vacancies per month\n",
    "if 'vacancy_weight_adj' in data_df.columns:\n",
    "    print('removing old iteration of monthly weights')\n",
    "    data_df = data_df.drop(axis = 1, labels = 'vacancy_weight_adj')\n",
    "    #data_df = data_df[keep_columns]\n",
    "\n",
    "\n",
    "#%%\n",
    "# Merge vacancy weights based on sic classification and month\n",
    "timer.start_task('joining new monthly weights')\n",
    "\n",
    "small_df = None\n",
    "# MERGING WEIGHTS WITHIN THE MAIN DATAFRAME\n",
    "data_df = pd.merge(data_df, joint_stock_weights, \n",
    "                               left_on = ['final_sic_letter','best_month'], \n",
    "                               right_on= ['sic_letter','best_month'],\n",
    "                               how = 'left')\n",
    "assert(old_len_data== len(data_df))\n",
    "\n",
    "data_df.vacancy_weight = data_df.vacancy_weight_adj\n",
    "timer.end_task()\n",
    "\n",
    "# multiply by the duration percentage\n",
    "data_df['vacancy_weight_adj'] = data_df.vacancy_weight * data_df.best_month_duration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale the per-vacancy weight by a monthly factor to increase alignment\n",
    "\n",
    "This function is used to scale the per-vacancy weights used to align the stock of online job vacancies with the stock of vacancies from the ONS survey. For more info see the docstring of the function 'scale_weights_by_total_levels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute the scaled weights\n",
    "new_weights_df = scale_weights_by_total_levels(joint_stock_weights.rename(\n",
    "    columns = {'sic_letter': 'final_sic_letter', 'vacancy_weight_adj': 'vacancy_weight'}), \n",
    "    raw_jvs, stock_per_month_full, sectors_in_common = shared_oja_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join up with main dataframe\n",
    "timer.start_task('joining dataframe to add re-scale adjustment weights')\n",
    "data_df = data_df.merge(new_weights_df[['best_month','final_sic_letter','vacancy_weight_new']], \n",
    "                        on = ['best_month','final_sic_letter'], how ='left')\n",
    "timer.end_task()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.rename(columns = {'vacancy_weights_new': 'vacancy_weight_new'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-compute the stock of vacancies and show the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% get new daily stock of vacancies\n",
    "timer.start_task('recomputing daily and monthly OJV stock')\n",
    "new_stock_per_month, _, _ , _ = get_stock_breakdown(data_df, agg_func = 'sum', \n",
    "                               agg_col = 'vacancy_weight_new', breakdown_col = 'final_sic_letter')\n",
    "timer.end_task()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot ONS and weighted OJA stock for each SIC letters separately. Total levels are likely to be different\n",
    "for col in shared_oja_names:\n",
    "    if col in ['A','T','uncertain']:\n",
    "        plt.plot(new_stock_per_month[col])\n",
    "        plt.title(\"Stock of 'uncertain' vacancies\")\n",
    "    else:\n",
    "        plt.figure(figsize = (8,8))\n",
    "        plt.plot(new_stock_per_month[col],label = 'OJV after')\n",
    "        plt.plot(1000*raw_jvs[col],'--',label='ONS')\n",
    "        plt.plot(stock_per_month[col],label = 'OJV before')\n",
    "        plt.xlabel('Date', fontsize = 13)\n",
    "        plt.ylabel('Vacancy stock', fontsize = 13)\n",
    "        plt.legend(fontsize = 13)\n",
    "        tmp = np.corrcoef(raw_jvs[col].astype('float'),new_stock_per_month[col])[0,1]\n",
    "        print((f\"Time series correlation for {sic_letter_to_text[col]} is \"\n",
    "               f\"{tmp:.3f}\"))\n",
    "        plt.title(sic_letter_to_text[col])\n",
    "        if SAVEFIGS:\n",
    "            plt.savefig(f\"{res_folder}/adjusted_stock_vs_raw_vs_ons_sic_{col}_single_axis\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the new stock per month with the un-weighted one\n",
    "joint_stock = joint_stock.merge(new_stock_per_month, left_index = True, \n",
    "                                right_index = True)\n",
    "joint_stock = joint_stock.rename(columns = \n",
    "                                 {col: col+'_sum' for col in new_stock_per_month.columns})\n",
    "joint_stock = joint_stock[sorted(joint_stock.columns)]\n",
    "joint_stock.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and show the correlation between ONS and OJA stock before (un-weighted) and after (weighted)\n",
    "for col in shared_oja_names: #new_stock_per_month.columns:\n",
    "    if col in ['A','T','uncertain']:\n",
    "        continue\n",
    "    print(f\"Correlation before and after for {col}\")\n",
    "    joint_stock[col+'_ons'] = joint_stock[col+'_ons'].astype('float')\n",
    "    print(joint_stock[[col+'_ons',col+'_counts',col+'_sum']].corr()[col+'_ons'])\n",
    "    print(f\"MSE before and after for {col}\")\n",
    "    mse_before = ((joint_stock[col+'_ons'] - joint_stock[col+'_counts']/1000)**2).sum()\n",
    "    mse_after = ((joint_stock[col+'_ons'] - joint_stock[col+'_sum']/1000)**2).mean()\n",
    "    print(pd.Series([mse_before,mse_after],index = [col + t for t in ['_counts','_sum']]))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save monthly weights to disk \n",
    "\n",
    "Do this so that we can load and join them with the main dataframe for future analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
